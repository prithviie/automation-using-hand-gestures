{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "491ad4fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tflearn\n",
    "from tensorflow.python.framework import ops\n",
    "from tflearn.layers.conv import conv_2d,max_pool_2d\n",
    "from tflearn.layers.core import input_data,dropout,fully_connected\n",
    "from tflearn.layers.estimator import regression\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7532be28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "['Dataset/Direction_left', 'Dataset/Direction_right', 'Dataset/Fist', 'Dataset/Five-palm', 'Dataset/Four', 'Dataset/OK', 'Dataset/One', 'Dataset/Stop', 'Dataset/Three', 'Dataset/Thumbs_down', 'Dataset/Thumbs_up', 'Dataset/Two']\n"
     ]
    }
   ],
   "source": [
    "# training without normalizing the image (scaling)\n",
    "dataset_dir = 'Dataset'\n",
    "\n",
    "checkpoint_path = 'TrainedModel/checkpoints/' + 'Gesture12RecognitionModel.tflearn'\n",
    "best_checkpoint_path = 'TrainedModel/checkpoints/' + 'Gesture12RecognitionModelBest.tflearn'\n",
    "saved_model_path = 'TrainedModel/' + 'Gesture12RecognitionModel.tflearn'\n",
    "\n",
    "test_ratio = 0.2\n",
    "validation_ratio = 0.2\n",
    "batch_size = 50\n",
    "epochs = 10\n",
    "\n",
    "all_images = []\n",
    "class_ids = []\n",
    "n_classes = len(os.listdir(dataset_dir))\n",
    "print(n_classes)\n",
    "\n",
    "alldirs = []\n",
    "for d in os.listdir(dataset_dir):\n",
    "    alldirs.append(f\"{dataset_dir}/{d}\")\n",
    "print(alldirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e89f383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset/Direction_left done.\n",
      "Dataset/Direction_right done.\n",
      "Dataset/Fist done.\n",
      "Dataset/Five-palm done.\n",
      "Dataset/Four done.\n",
      "Dataset/OK done.\n",
      "Dataset/One done.\n",
      "Dataset/Stop done.\n",
      "Dataset/Three done.\n",
      "Dataset/Thumbs_down done.\n",
      "Dataset/Thumbs_up done.\n",
      "Dataset/Two done.\n"
     ]
    }
   ],
   "source": [
    "for d in alldirs:\n",
    "    for img in os.listdir(d):\n",
    "        label = re.findall('[l]=[0-9]+', img)\n",
    "        label = label[0][2:]\n",
    "        \n",
    "        current_img = f\"{d}/{img}\"\n",
    "        image = cv2.imread(current_img)\n",
    "        gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        all_images.append(gray_image.reshape(89, 100, 1))\n",
    "        class_ids.append(label)\n",
    "    print(f\"{d} done.\")\n",
    "            \n",
    "all_images = np.array(all_images)\n",
    "class_ids = np.array(class_ids)\n",
    "\n",
    "# print(len(all_images))\n",
    "# print(len(class_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "882b58d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(all_images, class_ids, test_size=test_ratio)\n",
    "\n",
    "x_train, x_validation, y_train, y_validation = train_test_split(x_train, y_train, test_size=validation_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "287ef368",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train, n_classes)\n",
    "y_test = to_categorical(y_test, n_classes)\n",
    "y_validation = to_categorical(y_validation, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1dfb76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ops.reset_default_graph()\n",
    "#                           [batch, height, width, in_channels]\n",
    "convnet = input_data(shape=[None, 89, 100, 1], name='input')\n",
    "\n",
    "convnet = conv_2d(convnet, nb_filter=32, filter_size=2, activation='relu')\n",
    "convnet = max_pool_2d(convnet,  kernel_size=2)\n",
    "\n",
    "convnet = conv_2d(convnet, 64, 2, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 2)\n",
    "\n",
    "convnet = conv_2d(convnet, 128, 2, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 2)\n",
    "\n",
    "convnet = conv_2d(convnet, 256, 2, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 2)\n",
    "\n",
    "convnet = conv_2d(convnet, 256, 2, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 2)\n",
    "\n",
    "convnet = conv_2d(convnet, 128, 2, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 2)\n",
    "\n",
    "convnet = conv_2d(convnet, 64, 2, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 2)\n",
    "\n",
    "convnet = fully_connected(convnet, n_units=1000, activation='relu')\n",
    "convnet = dropout(convnet, keep_prob=0.75)\n",
    "# rate = 1 - keep_prob\n",
    "\n",
    "convnet = fully_connected(convnet, n_units=n_classes, activation='softmax')\n",
    "\n",
    "convnet = regression(convnet,\n",
    "                     optimizer='adam',\n",
    "                     learning_rate=0.001,\n",
    "                     loss='categorical_crossentropy',\n",
    "                     name='regression')\n",
    "\n",
    "model = tflearn.DNN(convnet, \n",
    "                    checkpoint_path=checkpoint_path, \n",
    "                    best_checkpoint_path=best_checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba92e50f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 1539  | total loss: \u001b[1m\u001b[32m0.04364\u001b[0m\u001b[0m | time: 109.442s\n",
      "| Adam | epoch: 010 | loss: 0.04364 - acc: 0.9962 -- iter: 7650/7680\n",
      "Training Step: 1540  | total loss: \u001b[1m\u001b[32m0.03928\u001b[0m\u001b[0m | time: 115.758s\n",
      "| Adam | epoch: 010 | loss: 0.03928 - acc: 0.9966 | val_loss: 0.03523 - val_acc: 0.9979 -- iter: 7680/7680\n",
      "--\n",
      "INFO:tensorflow:/media/prithvi/3F0CC364D83B1E93/prithvi/code/projects/hand-gesture/TrainedModel/checkpoints/Gesture12RecognitionModel.tflearn-1540 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "INFO:tensorflow:/media/prithvi/3F0CC364D83B1E93/prithvi/code/projects/hand-gesture/TrainedModel/checkpoints/Gesture12RecognitionModel.tflearn-1540 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "INFO:tensorflow:/media/prithvi/3F0CC364D83B1E93/prithvi/code/projects/hand-gesture/TrainedModel/Gesture12RecognitionModel.tflearn is not in all_model_checkpoint_paths. Manually adding it.\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train = shuffle(x_train, y_train, random_state=0)\n",
    "\n",
    "model.fit(x_train, y_train, n_epoch=epochs,\n",
    "          batch_size=batch_size, validation_set=(x_validation, y_validation),\n",
    "        snapshot_step=100, show_metric=True, run_id='convnet_coursera')\n",
    "\n",
    "model.save(saved_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e121e8c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99875]\n"
     ]
    }
   ],
   "source": [
    "# print(model.get_summary())\n",
    "\n",
    "score = model.evaluate(x_test, y_test)\n",
    "print(score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
