{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "491ad4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tflearn\n",
    "from tensorflow.python.framework import ops\n",
    "from tflearn.layers.conv import conv_2d,max_pool_2d\n",
    "from tflearn.layers.core import input_data,dropout,fully_connected\n",
    "from tflearn.layers.estimator import regression\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7532be28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "['Dataset/Direction_left', 'Dataset/Direction_right', 'Dataset/Fist', 'Dataset/Five-palm', 'Dataset/Four', 'Dataset/OK', 'Dataset/One', 'Dataset/Stop', 'Dataset/Three', 'Dataset/Thumbs_down', 'Dataset/Thumbs_up', 'Dataset/Two']\n"
     ]
    }
   ],
   "source": [
    "# training without normalizing the image (scaling)\n",
    "dataset_dir = 'Dataset'\n",
    "\n",
    "checkpoint_path = 'TrainedModel/checkpoints/' + 'Gesture12RecognitionModel.tflearn'\n",
    "best_checkpoint_path = 'TrainedModel/checkpoints/' + 'Gesture12RecognitionModelBest.tflearn'\n",
    "saved_model_path = 'TrainedModel/' + 'Gesture12RecognitionModel.tflearn'\n",
    "\n",
    "test_ratio = 0.2\n",
    "validation_ratio = 0.2\n",
    "batch_size = 50\n",
    "epochs = 10\n",
    "\n",
    "all_images = []\n",
    "class_ids = []\n",
    "n_classes = len(os.listdir(dataset_dir))\n",
    "print(n_classes)\n",
    "\n",
    "alldirs = []\n",
    "for d in os.listdir(dataset_dir):\n",
    "    alldirs.append(f\"{dataset_dir}/{d}\")\n",
    "print(alldirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e89f383",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-aa19f82b8b71>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mcurrent_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{d}/{img}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mgray_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for d in alldirs:\n",
    "    for img in os.listdir(d):\n",
    "        label = re.findall('[l]=[0-9]+', img)\n",
    "        label = label[0][2:]\n",
    "        \n",
    "        current_img = f\"{d}/{img}\"\n",
    "        image = cv2.imread(current_img)\n",
    "        gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        all_images.append(gray_image.reshape(89, 100, 1))\n",
    "        class_ids.append(label)\n",
    "    print(f\"{d} done.\")\n",
    "            \n",
    "all_images = np.array(all_images)\n",
    "class_ids = np.array(class_ids)\n",
    "\n",
    "# print(len(all_images))\n",
    "# print(len(class_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "882b58d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(all_images, class_ids, test_size=test_ratio)\n",
    "\n",
    "x_train, x_validation, y_train, y_validation = train_test_split(x_train, y_train, test_size=validation_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287ef368",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train, n_classes)\n",
    "y_test = to_categorical(y_test, n_classes)\n",
    "y_validation = to_categorical(y_validation, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1dfb76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ops.reset_default_graph()\n",
    "#                           [batch, height, width, in_channels]\n",
    "convnet = input_data(shape=[None, 89, 100, 1], name='input')\n",
    "\n",
    "convnet = conv_2d(convnet, nb_filter=32, filter_size=2, activation='relu')\n",
    "convnet = max_pool_2d(convnet,  kernel_size=2)\n",
    "\n",
    "convnet = conv_2d(convnet, 64, 2, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 2)\n",
    "\n",
    "convnet = conv_2d(convnet, 128, 2, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 2)\n",
    "\n",
    "convnet = conv_2d(convnet, 256, 2, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 2)\n",
    "\n",
    "convnet = conv_2d(convnet, 256, 2, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 2)\n",
    "\n",
    "convnet = conv_2d(convnet, 128, 2, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 2)\n",
    "\n",
    "convnet = conv_2d(convnet, 64, 2, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 2)\n",
    "\n",
    "convnet = fully_connected(convnet, n_units=1000, activation='relu')\n",
    "convnet = dropout(convnet, keep_prob=0.75)\n",
    "\n",
    "convnet = fully_connected(convnet, n_units=n_classes, activation='softmax')\n",
    "\n",
    "convnet = regression(convnet,\n",
    "                     optimizer='adam',\n",
    "                     learning_rate=0.001,\n",
    "                     loss='categorical_crossentropy',\n",
    "                     name='regression')\n",
    "\n",
    "model = tflearn.DNN(convnet, \n",
    "                    checkpoint_path=checkpoint_path, \n",
    "                    best_checkpoint_path=best_checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba92e50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = shuffle(x_train, y_train, random_state=0)\n",
    "\n",
    "model.fit(x_train, y_train, n_epoch=epochs,\n",
    "          batch_size=batch_size, validation_set=(x_validation, y_validation),\n",
    "        snapshot_step=100, show_metric=True, run_id='convnet_coursera')\n",
    "\n",
    "\n",
    "print(model.get_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e121e8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(x_test, y_test)\n",
    "print(score)\n",
    "\n",
    "model.save(saved_model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
